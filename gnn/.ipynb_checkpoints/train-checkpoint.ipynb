{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "## Imports for plotting\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import GATConv, GraphConv, TopKPooling, BatchNorm\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import mlflow.pytorch\n",
    "\n",
    "\n",
    "## RDKit\n",
    "import rdkit\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(geom_data.Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        # root = where data set is stored\n",
    "        super(ProteinDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.root = root\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "\n",
    "        return os.listdir(f'{self.root}/raw')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        '''\n",
    "        If ALL of these files are found in processed_dir, processing is skipped.\n",
    "        If one or more are NOT found, all files in raw_dir are processed again.\n",
    "        '''\n",
    "        inxs = []\n",
    "\n",
    "        for pdb in self.raw_paths:\n",
    "            inxs.append(pdb.split('/')[-1].split('.p')[0])\n",
    "\n",
    "        return [f'{i}.pt' for i in inxs]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        #self.data = self.raw_paths\n",
    "\n",
    "        for pdb in self.raw_paths:\n",
    "\n",
    "            try:\n",
    "                mol_obj = Chem.rdmolfiles.MolFromPDBFile(pdb)\n",
    "            except AttributeError:\n",
    "                os.remove(pdb)\n",
    "                continue\n",
    "\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(mol_obj)\n",
    "\n",
    "            if node_feats == 'NaN':\n",
    "                os.remove(pdb)\n",
    "                continue\n",
    "\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(mol_obj)\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(mol_obj)\n",
    "\n",
    "            label = self._get_labels(pdb)\n",
    "\n",
    "            # Create Data object\n",
    "            data = geom_data.Data(x=node_feats,\n",
    "                                  edge_index=edge_index,\n",
    "                                  edge_attr=edge_feats,\n",
    "                                  y=label)\n",
    "\n",
    "            i = pdb.split('/')[-1].split('.p')[0]\n",
    "\n",
    "            torch.save(data, os.path.join(self.processed_dir,f'{i}.pt'))\n",
    "\n",
    "    def _get_node_features(self, mol):\n",
    "        '''\n",
    "        Returns a 2d array of shape:\n",
    "        [Number of nodes, Node feature size]\n",
    "        '''\n",
    "        all_node_feats = []\n",
    "\n",
    "        try:\n",
    "            for atom in mol.GetAtoms():\n",
    "                '''\n",
    "                node_feats = []\n",
    "                node_feats.append(dist)\n",
    "                all_node_feats.append(node_feats)\n",
    "                '''\n",
    "                all_node_feats.append(atom.GetMass())\n",
    "        except AttributeError:\n",
    "            return 'NaN'\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float).reshape([-1,1])\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        '''\n",
    "        Returns a 2d array of shape:\n",
    "        [Number of edges, Edge feature size]\n",
    "        '''\n",
    "        all_edge_feats = []\n",
    "\n",
    "        dists = Chem.rdmolops.Get3DDistanceMatrix(mol)\n",
    "\n",
    "        # CA-CA Distances\n",
    "        for bond in mol.GetBonds():\n",
    "            '''\n",
    "            edge_feats = []\n",
    "            edge_feats.append(dist)\n",
    "            all_edge_feats.append(edge_feats)\n",
    "            '''\n",
    "            begin = bond.GetBeginAtomIdx()\n",
    "            end = bond.GetEndAtomIdx()\n",
    "\n",
    "            all_edge_feats.append(dists[begin,end])\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float).reshape([-1,1])\n",
    "\n",
    "    def _get_adjacency_info(self, mol):\n",
    "        '''\n",
    "        Need to look into this further\n",
    "        '''\n",
    "        adj_matrix = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
    "        row, col = np.where(adj_matrix)\n",
    "        coo = np.array(list(zip(row, col)))\n",
    "        coo = np.reshape(coo, (2, -1))\n",
    "        return torch.tensor(coo, dtype=torch.long)\n",
    "\n",
    "    def _get_labels(self, fn):\n",
    "\n",
    "        with open(fn, 'r') as f:\n",
    "            label = float(f.readline())\n",
    "            f.close()\n",
    "\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.raw_paths)\n",
    "\n",
    "    def get(self, inx):\n",
    "        '''\n",
    "        Same as '__getitem__'\n",
    "        (Not needed for PyG's InMemoryDataset class)\n",
    "        '''\n",
    "        data = torch.load(self.processed_paths[inx])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        embedding_size = 1024\n",
    "\n",
    "        # GNN Layers\n",
    "\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head1 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head2 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "        self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head3 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "        # Linear Layers\n",
    "\n",
    "        self.fc1 = Linear(embedding_size*2, 1024)\n",
    "        self.fc2 = Linear(1024, 128)\n",
    "        self.fc3 = Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "\n",
    "        # Reshaping\n",
    "        #print(x)\n",
    "        #x = x.view(1, 188)\n",
    "        #print(x)\n",
    "\n",
    "        # First block\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.head1(x)\n",
    "\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x,\n",
    "                                                                 edge_index,\n",
    "                                                                 None,\n",
    "                                                                 batch_index)\n",
    "\n",
    "        x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Second block\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.head2(x)\n",
    "\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x,\n",
    "                                                                 edge_index,\n",
    "                                                                 None,\n",
    "                                                                 batch_index)\n",
    "\n",
    "        x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Third block\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.head3(x)\n",
    "\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x,\n",
    "                                                                 edge_index,\n",
    "                                                                 None,\n",
    "                                                                 batch_index)\n",
    "\n",
    "        x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Concat pooled vectors\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        # Apply Linear Layers\n",
    "        x = self.fc1(x).relu()\n",
    "        x = self.fc2(x).relu()\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self, m):\n",
    "        # parameter initialization\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c04197",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d12614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Loading the dataset\n",
    "train_dataset = ProteinDataset(root=\"data/lys50_2/train\")\n",
    "test_dataset = ProteinDataset(root=\"data/lys50_2/test\")\n",
    "\n",
    "#%% Loading the model\n",
    "model = GNN(feature_size=train_dataset[0].x.shape[1])\n",
    "model = model.to(device)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0000025)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19be0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare training\n",
    "NUM_GRAPHS_PER_BATCH = 10\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        # Use GPU\n",
    "        batch.to(device)\n",
    "        # Reset gradients\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(),\n",
    "                                batch.edge_attr.float(),\n",
    "                                batch.edge_index,\n",
    "                                batch.batch)\n",
    "        # Calculating the loss and gradients\n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))\n",
    "        loss.backward()\n",
    "        # Update using the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    #calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)\n",
    "        pred = model(batch.x.float(),\n",
    "                        batch.edge_attr.float(),\n",
    "                        batch.edge_index,\n",
    "                        batch.batch)\n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))\n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    #calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    #print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    #print(f\"F1 Score: {f1_score(y_pred, y_true)}\")\n",
    "    #print(f\"Accuracy: {accuracy_score(y_pred, y_true)}\")\n",
    "    #print(f\"Precision: {precision_score(y_pred, y_true)}\")\n",
    "    #print(f\"Recall: {recall_score(y_pred, y_true)}\")\n",
    "    try:\n",
    "        roc = roc_auc_score(y_pred, y_true)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"ROC AUC: notdefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for training\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    loss = train(epoch=epoch).detach().cpu().numpy()\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        testloss = test(epoch=epoch).detach().cpu().numpy()\n",
    "        print(epoch, loss, testloss)\n",
    "    else:\n",
    "        print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    dataset = ProteinDataset(root='data/lys50_2/train')\n",
    "    for data in dataset:\n",
    "        print(data.y)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
