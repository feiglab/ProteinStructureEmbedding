{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ae7750",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3226f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fn):\n",
    "        data = np.genfromtxt(fn, delimiter=',')\n",
    "        #print(data)\n",
    "        self.label = data[:,1].astype(np.float32) # rgyr (could be tdiff,rdiff,vol)\n",
    "        self.input1 = data[:,2:-1].reshape((-1, 1, 1000))/10.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.label.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.input1[index].astype(np.float32), self.label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c999a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "toppath = '/home/spencer/ml/hpro'\n",
    "pathtodata = f'{toppath}/genscripts/cacofm/rgyr_more/cut'\n",
    "train_set = Dataset(f'{pathtodata}/rgyr.cacofm.training.other.csv') # load training data\n",
    "test_set = Dataset(f'{pathtodata}/rgyr.cacofm.test.other.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc290f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1,value=train_set[0] # gives first line of training set\n",
    "print(input1.shape, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17704a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25, shuffle=True, num_workers=2) # go thru data in batches of 25, optimizing based on that (take 25, adjust model ...)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=25, shuffle=False, num_workers=2)\n",
    "alltest_loader = torch.utils.data.DataLoader(test_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input1, label in train_loader:\n",
    "    print(input1.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # define layers to be used\n",
    "        self.conv_1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1) # convolutional layers will go over all 188x188 \"pixels\" of the matrix\n",
    "        self.conv_2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1) # starts with 1 channel, will convert to {in_channels}x188x188\n",
    "        self.conv_3 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, padding=1) # reduce channels to 64 ()\n",
    "        self.conv_4 = nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten(start_dim=1) # makes completely linear from matrix\n",
    "        self.fc_1 = nn.Linear(4000, 1000) # fully connected network\n",
    "        self.fc_2 = nn.Linear(1000, 250)\n",
    "        self.fc_3 = nn.Linear(250, 100) # fully connected network\n",
    "        self.fc_4 = nn.Linear(100, 25) # fully connected network\n",
    "        self.fc_5 = nn.Linear(25, 1) # fully connected network\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv_4(x)\n",
    "        x = F.relu(x)\n",
    "        # dimension conversion\n",
    "        x = self.flatten(x) # change dimension from 3d to 1d, does not change numbers\n",
    "\n",
    "        #apply fully connected layers\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.relu(self.fc_3(x))\n",
    "        x = F.relu(self.fc_4(x))\n",
    "        x = self.fc_5(x) # reduces dimension from 64\n",
    "\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self, m):\n",
    "        # parameter initialization\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6eb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model() # generate model\n",
    "model.to(\"cuda\") # run on GPU\n",
    "#model.apply(model.initialize_weights) # apply the fcn\n",
    "#model.zero_grad() # initialize gradients to zero\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00004)\n",
    "optimizerfine = torch.optim.Adam(model.parameters(), lr=0.0000005)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.00001, momentum=0.1)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e96f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss fcn\n",
    "loss_fn = nn.L1Loss() # determine what is a good soln or not (close as possible to rgyr vals) (basically MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(m,opt):\n",
    "    loss_sum = 0.0\n",
    "    for input1, label in train_loader:\n",
    "        opt.zero_grad()\n",
    "        input1 = input1.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        output = m(input1)\n",
    "        output = torch.flatten(output)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        opt.step()\n",
    "    return loss_sum / len(train_loader) #, accuracy\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d545a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if things are working\n",
    "def validate(m):\n",
    "    loss_sum = 0.0\n",
    "    accuracy = 0.0\n",
    "    for input1, label in alltest_loader:\n",
    "        input1 = input1.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        #\n",
    "        with torch.no_grad():\n",
    "            output = m(input1)\n",
    "        #\n",
    "        output=torch.flatten(output)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / len(alltest_loader)#, accuracy\n",
    "print(len(alltest_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b9d32",
   "metadata": {},
   "source": [
    "### Training for RGYR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(model.initialize_weights)\n",
    "model.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "optimizerfine.zero_grad()\n",
    "\n",
    "for i in range(21):\n",
    "    loss = train(model,optimizerfine)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(201):\n",
    "    loss = train(model,optimizer)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_weights = {'conv_1': model.conv_1.weight.data,\n",
    "                      'conv_2': model.conv_2.weight.data,\n",
    "                      'conv_3': model.conv_3.weight.data,\n",
    "                      'conv_4': model.conv_4.weight.data}\n",
    "torch.save(conv_layer_weights, './weights_rgyr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "nameoffile = input('FILENAME: ')\n",
    "torch.save(model.state_dict(), f'{toppath}/models/{nameoffile}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1db1ba",
   "metadata": {},
   "source": [
    "### Training for TDIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a132e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "toppath = '/home/spencer/ml/hpro'\n",
    "pathtodata = f'{toppath}/genscripts/cacofm/tdiff'\n",
    "train_set = Dataset(f'{pathtodata}/tdiff.training.csv') # load training data\n",
    "test_set = Dataset(f'{pathtodata}/tdiff.test.csv') # load test data\n",
    "\n",
    "input1,value=train_set[0] # gives first line of training set\n",
    "print(input1.shape, value)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25, shuffle=True, num_workers=2) # go thru data in batches of 25, optimizing based on that (take 25, adjust model ...)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=25, shuffle=False, num_workers=2)\n",
    "\n",
    "alltest_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "for input1, label in train_loader:\n",
    "    print(input1.size())\n",
    "    print(label.size())\n",
    "    break\n",
    "    \n",
    "model = Model() # generate model\n",
    "model.to(\"cuda\") # run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('./weights_rgyr.pth')\n",
    "model.conv_1.weight.data = weights['conv_1']\n",
    "model.conv_2.weight.data = weights['conv_2']\n",
    "model.conv_3.weight.data = weights['conv_3']\n",
    "model.conv_4.weight.data = weights['conv_4']\n",
    "model.conv_1.weight.requires_grad = False\n",
    "model.conv_2.weight.requires_grad = False\n",
    "model.conv_3.weight.requires_grad = False\n",
    "model.conv_4.weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00006)\n",
    "optimizerfine = torch.optim.Adam(model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf359fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(model.initialize_weights)\n",
    "model.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "optimizerfine.zero_grad()\n",
    "\n",
    "for i in range(21):\n",
    "    loss = train(model,optimizerfine)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75def492",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(201):\n",
    "    loss = train(model,optimizer)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "nameoffile = input('FILENAME: ')\n",
    "torch.save(model.state_dict(), f'{toppath}/models/{nameoffile}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7ce0e",
   "metadata": {},
   "source": [
    "### Training for RDIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "toppath = '/home/spencer/ml/hpro'\n",
    "pathtodata = f'{toppath}/genscripts/cacofm/rdiff'\n",
    "train_set = Dataset(f'{pathtodata}/rdiff.training.csv') # load training data\n",
    "test_set = Dataset(f'{pathtodata}/rdiff.test.csv') # load test data\n",
    "\n",
    "input1,value=train_set[0] # gives first line of training set\n",
    "print(input1.shape, value)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=25, shuffle=True, num_workers=2) # go thru data in batches of 25, optimizing based on that (take 25, adjust model ...)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=25, shuffle=False, num_workers=2)\n",
    "\n",
    "alltest_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "for input1, label in train_loader:\n",
    "    print(input1.size())\n",
    "    print(label.size())\n",
    "    break\n",
    "    \n",
    "model = Model() # generate model\n",
    "model.to(\"cuda\") # run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('./weights_rgyr.pth')\n",
    "model.conv_1.weight.data = weights['conv_1']\n",
    "model.conv_2.weight.data = weights['conv_2']\n",
    "model.conv_3.weight.data = weights['conv_3']\n",
    "model.conv_4.weight.data = weights['conv_4']\n",
    "model.conv_1.weight.requires_grad = False\n",
    "model.conv_2.weight.requires_grad = False\n",
    "model.conv_3.weight.requires_grad = False\n",
    "model.conv_4.weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00006)\n",
    "optimizerfine = torch.optim.Adam(model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1015244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(model.initialize_weights)\n",
    "model.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "optimizerfine.zero_grad()\n",
    "\n",
    "for i in range(21):\n",
    "    loss = train(model,optimizerfine)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(201):\n",
    "    loss = train(model,optimizer)\n",
    "    if (i%10==0) :\n",
    "       lossvalidate = validate(model)\n",
    "       print (i, loss, lossvalidate)\n",
    "    else :\n",
    "       print (i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "nameoffile = input('FILENAME: ')\n",
    "torch.save(model.state_dict(), f'{toppath}/models/{nameoffile}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
